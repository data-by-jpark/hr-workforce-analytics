{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6294718,"sourceType":"datasetVersion","datasetId":3620223}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Notebook Overview\n\n### HR Employee Dataset ‚Äì Data Cleaning (Raw ‚Üí Cleaned)\nThis notebook focuses on transforming raw HR data into an analysis-ready dataset.\n\n- Input: `employee_data.csv` (raw HR dataset)\n- Output: `cleaned_employee_data.csv` (analysis-ready dataset)\n\nThis notebook covers:\n1. Inspecting raw data quality (missing values, data types, duplicates)\n2. Cleaning and standardizing key fields (dates, categories)\n3. Fixing inconsistencies between employee status and termination information\n4. Handling missing, incorrect, or outlier values\n5. Creating core derived fields (IsActive, AttritionFlag, TenureDays)\n6. Exporting a cleaned dataset for HR Workforce analysis (Notebook 2)","metadata":{}},{"cell_type":"markdown","source":"# 1. Import Libraries & Load Raw Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npd.set_option(\"display.max_columns\", None)\n\n# Load raw dataset\ndf_raw = pd.read_csv(\"/kaggle/input/employeedataset/employee_data.csv\")\ndf_raw.head()\n\n# Fixed reference date for all time-based calculations\nanalysis_date = pd.Timestamp(\"2025-11-26\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:29.811777Z","iopub.execute_input":"2025-12-03T02:44:29.811941Z","iopub.status.idle":"2025-12-03T02:44:31.724055Z","shell.execute_reply.started":"2025-12-03T02:44:29.811919Z","shell.execute_reply":"2025-12-03T02:44:31.723359Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### üìå Explanation\nTo ensure reproducibility, this notebook uses a fixed **analysis date** to keep all time-based calculations (age, tenure, attrition) consistent. Using a static date prevents results from changing each time the notebook is rerun.","metadata":{}},{"cell_type":"markdown","source":"# 2. Inspect Basic Structure","metadata":{}},{"cell_type":"code","source":"# Basic overview of raw dataset\nprint(\"Shape (rows, cols):\", df_raw.shape)\nprint(\"\\nData Types:\")\ndf_raw.info()\n\nprint(\"\\nMissing Values:\")\nprint(df_raw.isnull().sum().sort_values(ascending=False))\n\nprint(\"\\nDuplicate Rows:\", df_raw.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.725626Z","iopub.execute_input":"2025-12-03T02:44:31.725848Z","iopub.status.idle":"2025-12-03T02:44:31.772784Z","shell.execute_reply.started":"2025-12-03T02:44:31.725828Z","shell.execute_reply":"2025-12-03T02:44:31.771856Z"}},"outputs":[{"name":"stdout","text":"Shape (rows, cols): (3000, 26)\n\nData Types:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3000 entries, 0 to 2999\nData columns (total 26 columns):\n #   Column                      Non-Null Count  Dtype \n---  ------                      --------------  ----- \n 0   EmpID                       3000 non-null   int64 \n 1   FirstName                   3000 non-null   object\n 2   LastName                    3000 non-null   object\n 3   StartDate                   3000 non-null   object\n 4   ExitDate                    1533 non-null   object\n 5   Title                       3000 non-null   object\n 6   Supervisor                  3000 non-null   object\n 7   ADEmail                     3000 non-null   object\n 8   BusinessUnit                3000 non-null   object\n 9   EmployeeStatus              3000 non-null   object\n 10  EmployeeType                3000 non-null   object\n 11  PayZone                     3000 non-null   object\n 12  EmployeeClassificationType  3000 non-null   object\n 13  TerminationType             3000 non-null   object\n 14  TerminationDescription      1533 non-null   object\n 15  DepartmentType              3000 non-null   object\n 16  Division                    3000 non-null   object\n 17  DOB                         3000 non-null   object\n 18  State                       3000 non-null   object\n 19  JobFunctionDescription      3000 non-null   object\n 20  GenderCode                  3000 non-null   object\n 21  LocationCode                3000 non-null   int64 \n 22  RaceDesc                    3000 non-null   object\n 23  MaritalDesc                 3000 non-null   object\n 24  Performance Score           3000 non-null   object\n 25  Current Employee Rating     3000 non-null   int64 \ndtypes: int64(3), object(23)\nmemory usage: 609.5+ KB\n\nMissing Values:\nTerminationDescription        1467\nExitDate                      1467\nEmpID                            0\nPerformance Score                0\nMaritalDesc                      0\nRaceDesc                         0\nLocationCode                     0\nGenderCode                       0\nJobFunctionDescription           0\nState                            0\nDOB                              0\nDivision                         0\nDepartmentType                   0\nTerminationType                  0\nFirstName                        0\nEmployeeClassificationType       0\nPayZone                          0\nEmployeeType                     0\nEmployeeStatus                   0\nBusinessUnit                     0\nADEmail                          0\nSupervisor                       0\nTitle                            0\nStartDate                        0\nLastName                         0\nCurrent Employee Rating          0\ndtype: int64\n\nDuplicate Rows: 0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### üìå Key Findings\n- Dataset contains **3,000 rows √ó 26 columns** (employee-level records), which is an adequate size for workforce-level exploratory analysis.\n- Several object columns should be converted to **categorical** types for cleaner analysis and better memory efficiency.\n- **Date fields** (StartDate, ExitDate, DOB) are stored as strings and need conversion to `datetime` for accurate tenure, hiring, and attrition calculations.\n- Missing ExitDate and TerminationDescription values align with active employees, which is expected.\n- No duplicate rows were found.","metadata":{}},{"cell_type":"markdown","source":"# 3. Create Working Copy\n\nTo keep the raw dataset intact, I created a working copy (`df`) and selected only the fields needed for workforce, headcount, and attrition analysis.\n\n### üóÇÔ∏è Column Classification\n- **Required columns**: Core HR fields used to calculate hiring, termination, headcount, and attrition metrics\n- **Optional columns**: Useful for segmentation or additional insights\n- **Excluded Columns**: Not relevant to this project and removed to reduce noise\n\n| **Required Columns** | **Optional Columns** | **Excluded Columns**            |\n|:---------------------|:---------------------|:-------------------------------|\n| EmpID                | Title                | EmployeeClassificationType     |\n| StartDate            | Division             | TerminationDescription         |\n| ExitDate             | PayZone              | JobFunctionDescription         |\n| BusinessUnit         | DOB                  | Supervisor                     |\n| DepartmentType       | GenderCode           | State                          |\n| EmployeeStatus       | RaceDesc             | MaritalDesc                    |\n| EmployeeType         | LocationCode         | Performance Score              |\n| TerminationType      | FirstName            | Current Employee Rating        |\n|                      | LastName             |                                |\n|                      | ADEmail              |                                |","metadata":{}},{"cell_type":"code","source":"# Make a working copy\ndf = df_raw.copy()\n\n# Define column groups\nrequired_cols = [\n    'EmpID', 'StartDate', 'ExitDate',\n    'BusinessUnit', 'DepartmentType',\n    'EmployeeStatus', 'EmployeeType',\n    'TerminationType'\n]\n\noptional_cols = [\n    'Title', 'Division', 'PayZone',\n    'DOB', 'GenderCode', 'RaceDesc', 'LocationCode',\n    'FirstName', 'LastName', 'ADEmail'\n]\n\ndrop_cols = [\n    'EmployeeClassificationType', 'TerminationDescription', 'JobFunctionDescription',\n    'Supervisor', 'State', 'MaritalDesc',\n    'Performance Score', 'Current Employee Rating'\n]\n\n# Drop unnecessary columns\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns])\n\n# Keep only required + optional columns\nkeep_cols = [c for c in (required_cols + optional_cols) if c in df.columns]\ndf = df[keep_cols]\n\nprint(\"Columns retained for analysis:\")\nprint(df.columns.tolist())\nprint(\"\\nShape:\", df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.773901Z","iopub.execute_input":"2025-12-03T02:44:31.774169Z","iopub.status.idle":"2025-12-03T02:44:31.787781Z","shell.execute_reply.started":"2025-12-03T02:44:31.774143Z","shell.execute_reply":"2025-12-03T02:44:31.786767Z"}},"outputs":[{"name":"stdout","text":"Columns retained for analysis:\n['EmpID', 'StartDate', 'ExitDate', 'BusinessUnit', 'DepartmentType', 'EmployeeStatus', 'EmployeeType', 'TerminationType', 'Title', 'Division', 'PayZone', 'DOB', 'GenderCode', 'RaceDesc', 'LocationCode', 'FirstName', 'LastName', 'ADEmail']\n\nShape: (3000, 18)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 4. Data Quality Audit & Cleaning\n\nIn this step, I performed a combined data quality audit and cleaning process. Each issue is first validated (audit) and then immediately corrected (cleaning),\nfollowing the same criteria used during the Excel-based review.\n\n### üóÇÔ∏è Audit Checklist\n| Check Category | What I Validate | Python Method |\n|----------------|------------------|---------------|\n| **1. Date Validation** | Convert to datetime, validate StartDate/ExitDate logic | `to_datetime`, `DateOffset`, logical filtering |\n| **2. Categorical Columns Inspection & Standardization** | Check label consistency and remove whitespace | `unique()`, `str.strip()` |\n| **3. Unique ID Check** | EmpID and names/emails not duplicated | `duplicated()` |\n| **4. Unrealistic Values** | DOB outliers (valid age 18‚Äì70) | `to_datetime`, age-based filtering |\n| **5. Cross-field Consistency** | EmployeeStatus ‚Üî ExitDate ‚Üî TerminationType alignment | logical conditions, boolean masking |\n| **6. Derived Variables** | IsActive, AttritionFlag, TenureDays | rule-based calculations |\n","metadata":{}},{"cell_type":"markdown","source":"## 4-1. Date Validation\nThe date fields (`StartDate`, `ExitDate`, `DOB`) were stored in mixed formats, so each field was converted to `datetime` for accurate age, tenure, and employment timeline calculations.\n\nTo mirror how Monthly Workforce Snapshots are handled in real HR analytics, all employment dates were shifted by **+2 years and 3 months**, aligning the dataset to **November 2025** and matching the timeline of this project. This preserves all original employment sequences while providing a consistent reference point for downstream metrics such as tenure, age, employment status, and attrition.\n\n### ‚úîÔ∏è Steps Performed\n1. Converted all date fields to `datetime` using explicit formats.  \n2. Applied a **+2 years, +3 months synthetic shift** to simulate a snapshot as of **November 2025**.  \n3. Validated employment timelines by identifying:  \n   - `StartDate > ExitDate` (invalid)  \n   - `StartDate == ExitDate` (same-day hire/termination)","metadata":{}},{"cell_type":"code","source":"# 1) Convert raw date strings to datetime\ndf['StartDate'] = pd.to_datetime(df['StartDate'], format=\"%d-%b-%y\", errors=\"coerce\")\ndf['ExitDate']  = pd.to_datetime(df['ExitDate'],  format=\"%d-%b-%y\", errors=\"coerce\")\ndf['DOB']       = pd.to_datetime(df['DOB'],       format=\"%d-%m-%Y\", errors=\"coerce\")\n\ndf[['StartDate', 'ExitDate', 'DOB']].head()\ndf[['StartDate', 'ExitDate', 'DOB']].dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.788920Z","iopub.execute_input":"2025-12-03T02:44:31.789532Z","iopub.status.idle":"2025-12-03T02:44:31.830026Z","shell.execute_reply.started":"2025-12-03T02:44:31.789502Z","shell.execute_reply":"2025-12-03T02:44:31.829230Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"StartDate    datetime64[ns]\nExitDate     datetime64[ns]\nDOB          datetime64[ns]\ndtype: object"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 2) Synthetic date shift: +2 years, +3 months (simulate Nov 2025 snapshot)\n\n# Before shift (date only)\nbefore_start_min = df['StartDate'].min().date()\nbefore_start_max = df['StartDate'].max().date()\nbefore_exit_min  = df['ExitDate'].min().date()\nbefore_exit_max  = df['ExitDate'].max().date()\n\n# Apply shift (for both StartDate & ExitDate)\nshift = pd.DateOffset(years=2, months=3)\nfor col in ['StartDate', 'ExitDate']:\n    df[col] = df[col] + shift\n\n# After shift (date only)\nafter_start_min = df['StartDate'].min().date()\nafter_start_max = df['StartDate'].max().date()\nafter_exit_min  = df['ExitDate'].min().date()\nafter_exit_max  = df['ExitDate'].max().date()\n\n# Create StartDate comparison table\nstartdate_comparison = pd.DataFrame({\n    \"StartDate (min)\": [before_start_min, after_start_min],\n    \"StartDate (max)\": [before_start_max, after_start_max]\n}, index=[\"Before Shift\", \"After Shift\"])\n\n# Create ExitDate comparison table\nexitdate_comparison = pd.DataFrame({\n    \"ExitDate (min)\": [before_exit_min, after_exit_min],\n    \"ExitDate (max)\": [before_exit_max, after_exit_max]\n}, index=[\"Before Shift\", \"After Shift\"])\n\nstartdate_comparison, exitdate_comparison","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.831107Z","iopub.execute_input":"2025-12-03T02:44:31.831326Z","iopub.status.idle":"2025-12-03T02:44:31.874214Z","shell.execute_reply.started":"2025-12-03T02:44:31.831281Z","shell.execute_reply":"2025-12-03T02:44:31.873491Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(             StartDate (min) StartDate (max)\n Before Shift      2018-08-07      2023-08-06\n After Shift       2020-11-07      2025-11-06,\n              ExitDate (min) ExitDate (max)\n Before Shift     2018-11-19     2023-08-06\n After Shift      2021-02-19     2025-11-06)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# 3) Identify invalid and same-day cases\ninvalid_condition = (\n    df['StartDate'].notna() &\n    df['ExitDate'].notna() &\n    (df['StartDate'] > df['ExitDate'])\n)\n\nsame_day_condition = (\n    df['StartDate'].notna() &\n    df['ExitDate'].notna() &\n    (df['StartDate'] == df['ExitDate'])\n)\n\n# Show counts\nprint(\"Invalid (StartDate > ExitDate):\", invalid_condition.sum())\nprint(\"Same-day Start/Exit:\", same_day_condition.sum())\n\n# Display same-day hire/termination cases\nprint(\"\\nReview of same-day hire/termination cases:\")\ndisplay(df[same_day_condition][['EmpID', 'StartDate','ExitDate', 'EmployeeStatus', 'TerminationType', 'DOB']])\n\n# Add same-day termination flag\ndf[\"SameDayTermination\"] = same_day_condition","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.875022Z","iopub.execute_input":"2025-12-03T02:44:31.875237Z","iopub.status.idle":"2025-12-03T02:44:31.902699Z","shell.execute_reply.started":"2025-12-03T02:44:31.875222Z","shell.execute_reply":"2025-12-03T02:44:31.901520Z"}},"outputs":[{"name":"stdout","text":"Invalid (StartDate > ExitDate): 0\nSame-day Start/Exit: 6\n\nReview of same-day hire/termination cases:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      EmpID  StartDate   ExitDate          EmployeeStatus TerminationType  \\\n241    3668 2025-11-06 2025-11-06                  Active       Voluntary   \n443    3870 2025-06-11 2025-06-11                  Active     Resignation   \n1357   1784 2025-11-02 2025-11-02                  Active      Retirement   \n1523   1950 2025-10-21 2025-10-21  Voluntarily Terminated     Involuntary   \n1543   1970 2024-07-21 2024-07-21                  Active      Retirement   \n1639   2066 2025-11-04 2025-11-04                  Active       Voluntary   \n\n            DOB  \n241  1996-05-24  \n443  1966-11-23  \n1357 1971-03-30  \n1523 1958-03-24  \n1543 1952-04-17  \n1639 1989-05-25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EmpID</th>\n      <th>StartDate</th>\n      <th>ExitDate</th>\n      <th>EmployeeStatus</th>\n      <th>TerminationType</th>\n      <th>DOB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>241</th>\n      <td>3668</td>\n      <td>2025-11-06</td>\n      <td>2025-11-06</td>\n      <td>Active</td>\n      <td>Voluntary</td>\n      <td>1996-05-24</td>\n    </tr>\n    <tr>\n      <th>443</th>\n      <td>3870</td>\n      <td>2025-06-11</td>\n      <td>2025-06-11</td>\n      <td>Active</td>\n      <td>Resignation</td>\n      <td>1966-11-23</td>\n    </tr>\n    <tr>\n      <th>1357</th>\n      <td>1784</td>\n      <td>2025-11-02</td>\n      <td>2025-11-02</td>\n      <td>Active</td>\n      <td>Retirement</td>\n      <td>1971-03-30</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>1950</td>\n      <td>2025-10-21</td>\n      <td>2025-10-21</td>\n      <td>Voluntarily Terminated</td>\n      <td>Involuntary</td>\n      <td>1958-03-24</td>\n    </tr>\n    <tr>\n      <th>1543</th>\n      <td>1970</td>\n      <td>2024-07-21</td>\n      <td>2024-07-21</td>\n      <td>Active</td>\n      <td>Retirement</td>\n      <td>1952-04-17</td>\n    </tr>\n    <tr>\n      <th>1639</th>\n      <td>2066</td>\n      <td>2025-11-04</td>\n      <td>2025-11-04</td>\n      <td>Active</td>\n      <td>Voluntary</td>\n      <td>1989-05-25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### üìå Key Findings\n- All date fields were successfully converted to `datetime`.\n- Synthetic date shifting aligns the dataset to a **November 2025 snapshot** while preserving original timelines.\n- **Same-day hire/termination**: 6 cases (retained and flagged).\n- **Invalid timelines (StartDate > ExitDate)**: 0 cases.\n- Clean date fields now support accurate tenure, age, and attrition calculations.","metadata":{}},{"cell_type":"markdown","source":"## 4-2. Categorical Columns Inspection & Standardization\n\nMost categorical fields in this HR dataset were already clean, with only minor issues such as trailing spaces in `DepartmentType` and `Title`. Light normalization was applied to ensure consistent category labels for grouping and downstream HR logic checks.\n\n### ‚úîÔ∏è Steps Performed\n1. Identified all categorical (`object`/`category`) fields.  \n2. Reviewed unique values to detect formatting inconsistencies.  \n3. Saved a snapshot of raw categorical values for before/after comparison.  \n4. Applied minimal cleaning (trim whitespace).  \n5. Compared before/after counts to confirm merged labels.  \n6. Converted categorical fields to `category` dtype for memory efficiency and faster grouping.","metadata":{}},{"cell_type":"code","source":"# 1) Identify categorical columns\ncat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\ncat_cols\n\n# 2) Inspect unique values (Before cleaning)\nfor col in cat_cols:\n    print(f\"\\n--- {col} ---\")\n    print(df[col].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.905395Z","iopub.execute_input":"2025-12-03T02:44:31.905640Z","iopub.status.idle":"2025-12-03T02:44:31.917974Z","shell.execute_reply.started":"2025-12-03T02:44:31.905622Z","shell.execute_reply":"2025-12-03T02:44:31.917099Z"}},"outputs":[{"name":"stdout","text":"\n--- BusinessUnit ---\n['CCDR' 'EW' 'PL' 'TNS' 'BPC' 'WBL' 'NEL' 'SVG' 'MSC' 'PYZ']\n\n--- DepartmentType ---\n['Production       ' 'Sales' 'IT/IS' 'Executive Office'\n 'Software Engineering' 'Admin Offices']\n\n--- EmployeeStatus ---\n['Active' 'Future Start' 'Voluntarily Terminated' 'Leave of Absence'\n 'Terminated for Cause']\n\n--- EmployeeType ---\n['Contract' 'Full-Time' 'Part-Time']\n\n--- TerminationType ---\n['Unk' 'Involuntary' 'Resignation' 'Retirement' 'Voluntary']\n\n--- Title ---\n['Production Technician I' 'Area Sales Manager' 'Production Technician II'\n 'IT Support' 'Network Engineer' 'Sr. Network Engineer'\n 'Principal Data Architect' 'Enterprise Architect' 'Sr. DBA'\n 'Database Administrator' 'Data Analyst' 'Data Analyst ' 'Data Architect'\n 'CIO' 'BI Director' 'Sr. Accountant' 'Software Engineering Manager'\n 'Software Engineer' 'Shared Services Manager' 'Senior BI Developer'\n 'Production Manager' 'President & CEO' 'Administrative Assistant'\n 'Accountant I' 'BI Developer' 'Sales Manager' 'IT Manager - Support'\n 'IT Manager - Infra' 'IT Manager - DB' 'Director of Sales'\n 'Director of Operations' 'IT Director']\n\n--- Division ---\n['Finance & Accounting' 'Aerial' 'General - Sga' 'General - Con'\n 'Field Operations' 'General - Eng' 'Engineers' 'Executive' 'Splicing'\n 'Project Management - Con' 'Fielders' 'Project Management - Eng'\n 'Shop (Fleet)' 'Wireline Construction' 'Catv' 'Yard (Material Handling)'\n 'Wireless' 'People Services' 'Underground' 'Billable Consultants'\n 'Technology / It' 'Sales & Marketing' 'Safety' 'Isp' 'Corp Operations']\n\n--- PayZone ---\n['Zone C' 'Zone A' 'Zone B']\n\n--- GenderCode ---\n['Female' 'Male']\n\n--- RaceDesc ---\n['White' 'Hispanic' 'Other' 'Black' 'Asian']\n\n--- FirstName ---\n['Uriah' 'Paula' 'Edward' ... 'Brenda' 'Jovanny' 'Jakobe']\n\n--- LastName ---\n['Bridges' 'Small' 'Buck' ... 'Hooper' 'Santiago' 'Erickson']\n\n--- ADEmail ---\n['uriah.bridges@bilearner.com' 'paula.small@bilearner.com'\n 'edward.buck@bilearner.com' ... 'annabel.wilkins@bilearner.com'\n 'kendra.braun@bilearner.com' 'chace.kerr@bilearner.com']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 3) Save snapshot (Before cleaning)\n# Columns affected by cleanup\nclean_cols = [\"DepartmentType\", \"Title\"]\n\n# Save original values for comparison\ncat_before = df[clean_cols].copy()\n\n# 4) Apply minimal cleaning\n# Strip leading/trailing whitespace\ndf[\"DepartmentType\"] = df[\"DepartmentType\"].str.strip()\ndf[\"Title\"] = df[\"Title\"].str.strip()\n\n# 5) Before vs After comparison\ndef show_clean_diff(col):\n    print(f\"\\n=== Clean Diff ‚Äî {col} ===\")\n    \n    wrap = lambda x: f\"‚ü¶{x}‚üß\"\n\n    before = cat_before[col].astype(str)\n    after = df[col].astype(str)\n\n    before_counts = before.value_counts()\n    after_counts = after.value_counts()\n\n    changed_labels = set(before[before != after])\n\n    rows = []\n\n    # Original ‚Üí Cleaned changes\n    for v in changed_labels:\n        rows.append({\n            col: wrap(v),\n            \"Before\": before_counts.get(v, 0),\n            \"After\": after_counts.get(v, 0)\n        })\n\n    # Show merged clean label\n    for v in changed_labels:\n        merged_to = df.loc[before == v, col].iloc[0]\n        if merged_to not in changed_labels:  # Avoid duplicates\n            rows.append({\n                col: wrap(merged_to),\n                \"Before\": before_counts.get(merged_to, 0),\n                \"After\": after_counts.get(merged_to, 0)\n            })\n\n    display(pd.DataFrame(rows))\n\nshow_clean_diff(\"DepartmentType\")\nshow_clean_diff(\"Title\")\n\n# 6) Convert to category dtype\nfor col in cat_cols:\n    df[col] = df[col].astype(\"category\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.918723Z","iopub.execute_input":"2025-12-03T02:44:31.919353Z","iopub.status.idle":"2025-12-03T02:44:31.985997Z","shell.execute_reply.started":"2025-12-03T02:44:31.919329Z","shell.execute_reply":"2025-12-03T02:44:31.985358Z"}},"outputs":[{"name":"stdout","text":"\n=== Clean Diff ‚Äî DepartmentType ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        DepartmentType  Before  After\n0  ‚ü¶Production       ‚üß    2020      0\n1         ‚ü¶Production‚üß       0   2020","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DepartmentType</th>\n      <th>Before</th>\n      <th>After</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>‚ü¶Production       ‚üß</td>\n      <td>2020</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>‚ü¶Production‚üß</td>\n      <td>0</td>\n      <td>2020</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n=== Clean Diff ‚Äî Title ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             Title  Before  After\n0  ‚ü¶Data Analyst ‚üß       8      0\n1   ‚ü¶Data Analyst‚üß      47     55","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Before</th>\n      <th>After</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>‚ü¶Data Analyst ‚üß</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>‚ü¶Data Analyst‚üß</td>\n      <td>47</td>\n      <td>55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"### üìå Key Insights\n\n- Only minor inconsistencies were found, primarily trailing spaces in `DepartmentType` and `Title`.\n- After trimming whitespace, duplicate labels were merged correctly without altering category meaning.\n- All categorical fields are now standardized and stored as `category` dtype, improving memory usage and ensuring consistent values for downstream analysis.","metadata":{}},{"cell_type":"markdown","source":"## 4-3. Unique ID Check\n\nTo ensure each employee is uniquely identifiable, the dataset was checked for duplicate values across key identifiers: `EmpID`, full name combinations, and email addresses.","metadata":{}},{"cell_type":"code","source":"# Check duplicated EmpID\nprint(\"Duplicate EmpID:\", df['EmpID'].duplicated().sum())\n\n# Create full-name field\ndf['FullName'] = (\n    df['FirstName'].astype(str).str.strip() + \"_\" +\n    df['LastName'].astype(str).str.strip()\n)\n\nprint(\"Duplicate FullName:\", df['FullName'].duplicated().sum())\n\n# Check duplicated email if available\nif 'ADEmail' in df.columns:\n    print(\"Duplicate ADEmail:\", df['ADEmail'].duplicated().sum())\n\n# Display duplicated full-name groups\nprint(\"\\nReview of duplicated FullName records:\")\nname_dupes = df[df['FullName'].duplicated(keep=False)].sort_values(by='FullName')\ndisplay(name_dupes[['EmpID','FirstName','LastName','ADEmail','StartDate','ExitDate']].head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:31.986509Z","iopub.execute_input":"2025-12-03T02:44:31.986673Z","iopub.status.idle":"2025-12-03T02:44:32.027808Z","shell.execute_reply.started":"2025-12-03T02:44:31.986657Z","shell.execute_reply":"2025-12-03T02:44:32.026041Z"}},"outputs":[{"name":"stdout","text":"Duplicate EmpID: 0\nDuplicate FullName: 2\nDuplicate ADEmail: 2\n\nReview of duplicated FullName records:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      EmpID FirstName LastName                       ADEmail  StartDate  \\\n1974   2401    Darien    Young    darien.young@bilearner.com 2025-02-09   \n2204   2631    Darien    Young    darien.young@bilearner.com 2023-06-03   \n865    1292   Larissa   Warner  larissa.warner@bilearner.com 2021-01-27   \n1742   2169   Larissa   Warner  larissa.warner@bilearner.com 2022-10-04   \n\n       ExitDate  \n1974 2025-04-10  \n2204        NaT  \n865         NaT  \n1742 2024-08-11  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EmpID</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n      <th>ADEmail</th>\n      <th>StartDate</th>\n      <th>ExitDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1974</th>\n      <td>2401</td>\n      <td>Darien</td>\n      <td>Young</td>\n      <td>darien.young@bilearner.com</td>\n      <td>2025-02-09</td>\n      <td>2025-04-10</td>\n    </tr>\n    <tr>\n      <th>2204</th>\n      <td>2631</td>\n      <td>Darien</td>\n      <td>Young</td>\n      <td>darien.young@bilearner.com</td>\n      <td>2023-06-03</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>1292</td>\n      <td>Larissa</td>\n      <td>Warner</td>\n      <td>larissa.warner@bilearner.com</td>\n      <td>2021-01-27</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>1742</th>\n      <td>2169</td>\n      <td>Larissa</td>\n      <td>Warner</td>\n      <td>larissa.warner@bilearner.com</td>\n      <td>2022-10-04</td>\n      <td>2024-08-11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### üìå Key Insights\n\n- No duplicated `EmpID` values were found.  \n- Duplicate full-name and email entries were identified.\n- These will be addressed in subsequent cleaning steps as part of the overall quality assurance process.","metadata":{}},{"cell_type":"markdown","source":"## 4-4. Realistic DOB (18‚Äì70 years)\n\nTo ensure that workforce metrics are based on realistic age values, I derived an `Age` column from `DOB` and applied a realistic age range filter (18 ‚â§ Age < 70). Employees outside this range are likely due to data entry or export errors (e.g., wrong year, default values), so they are treated as DOB outliers and removed from the analytical dataset.\n\nThis step prevents unrealistic ages from distorting headcount, tenure, and attrition insights. It also resolves previously detected duplicate name/email records that were tied to invalid DOB values.","metadata":{}},{"cell_type":"code","source":"# 1) Ensure DOB is parsed correctly (DD-MM-YYYY, day-first)\ndf['DOB'] = pd.to_datetime(df['DOB'], dayfirst=True, errors='coerce')\n\n# 2) Compute Age using fixed reference date\nref_date = analysis_date  \ndf['Age'] = ((ref_date - df['DOB']) / pd.Timedelta(days=365.25)).round(1)\n\nprint(\"Age distribution:\")\nprint(df['Age'].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.028474Z","iopub.execute_input":"2025-12-03T02:44:32.028642Z","iopub.status.idle":"2025-12-03T02:44:32.049482Z","shell.execute_reply.started":"2025-12-03T02:44:32.028628Z","shell.execute_reply":"2025-12-03T02:44:32.048856Z"}},"outputs":[{"name":"stdout","text":"Age distribution:\ncount    3000.000000\nmean       54.210467\nstd        17.688106\nmin        24.400000\n25%        38.200000\n50%        53.900000\n75%        69.500000\nmax        84.300000\nName: Age, dtype: float64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 3) Define realistic vs outlier age masks\nage = df['Age']\nrealistic_mask = age.notna() & (age >= 18) & (age < 70)\ndob_outliers_mask = age.notna() & ~realistic_mask\n\n# 4) Summary before filtering\ntotal = len(df)\nrealistic_count = realistic_mask.sum()\noutliers_count = dob_outliers_mask.sum()\n\nprint(f\"Total employees: {total}\")\nprint(f\"Realistic DOB (18‚Äì70): {realistic_count} ({realistic_count/total*100:.1f}%)\")\nprint(f\"Unrealistic DOB (<18 or ‚â•70): {outliers_count} ({outliers_count/total*100:.1f}%)\")\n\nprint(\"\\nSample DOB outliers:\")\ndisplay(df[dob_outliers_mask][['EmpID','FirstName','LastName','DOB','Age']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.050369Z","iopub.execute_input":"2025-12-03T02:44:32.050626Z","iopub.status.idle":"2025-12-03T02:44:32.065469Z","shell.execute_reply.started":"2025-12-03T02:44:32.050607Z","shell.execute_reply":"2025-12-03T02:44:32.064645Z"}},"outputs":[{"name":"stdout","text":"Total employees: 3000\nRealistic DOB (18‚Äì70): 2280 (76.0%)\nUnrealistic DOB (<18 or ‚â•70): 720 (24.0%)\n\nSample DOB outliers:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    EmpID FirstName LastName        DOB   Age\n5    3432     Maruk   Fraval 1949-04-03  76.6\n6    3433     Latia    Costa 1942-07-01  83.4\n9    3436    Joseph  Martins 1949-11-11  76.0\n11   3438    Dheepa   Nguyen 1948-04-06  77.6\n13   3440      Xana    Potts 1951-11-06  74.1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EmpID</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n      <th>DOB</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>3432</td>\n      <td>Maruk</td>\n      <td>Fraval</td>\n      <td>1949-04-03</td>\n      <td>76.6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3433</td>\n      <td>Latia</td>\n      <td>Costa</td>\n      <td>1942-07-01</td>\n      <td>83.4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3436</td>\n      <td>Joseph</td>\n      <td>Martins</td>\n      <td>1949-11-11</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3438</td>\n      <td>Dheepa</td>\n      <td>Nguyen</td>\n      <td>1948-04-06</td>\n      <td>77.6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3440</td>\n      <td>Xana</td>\n      <td>Potts</td>\n      <td>1951-11-06</td>\n      <td>74.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# 5) Check duplicates before filtering\ndup_fullname_before = df['FullName'].duplicated().sum() if 'FullName' in df.columns else 0\ndup_email_before = df['ADEmail'].duplicated().sum() if 'ADEmail' in df.columns else 0\n\n# 6) Filter unrealistic DOBs\ndf = df[realistic_mask].reset_index(drop=True)\n\n# 7) Check duplicates after filtering\ndup_fullname_after = df['FullName'].duplicated().sum() if 'FullName' in df.columns else 0\ndup_email_after = df['ADEmail'].duplicated().sum() if 'ADEmail' in df.columns else 0\n\nprint(\"\\nDuplicate Check (Before ‚Üí After DOB Filtering)\")\nprint(f\"- FullName: {dup_fullname_before} ‚Üí {dup_fullname_after}\")\nprint(f\"- ADEmail:  {dup_email_before} ‚Üí {dup_email_after}\")\nprint(\"\\nCleaned dataset shape:\", df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.066075Z","iopub.execute_input":"2025-12-03T02:44:32.066228Z","iopub.status.idle":"2025-12-03T02:44:32.082104Z","shell.execute_reply.started":"2025-12-03T02:44:32.066213Z","shell.execute_reply":"2025-12-03T02:44:32.080741Z"}},"outputs":[{"name":"stdout","text":"\nDuplicate Check (Before ‚Üí After DOB Filtering)\n- FullName: 2 ‚Üí 0\n- ADEmail:  2 ‚Üí 0\n\nCleaned dataset shape: (2280, 21)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### üìå Key Insights\n\n- The Age distribution indicated significant DOB inconsistencies, including values as high as 84 years, suggesting data entry or export errors.\n- Approximately **76%** of employees fell within the realistic 18‚Äì70 age range, while the remaining **24%** were excluded to prevent distortion in tenure, headcount, and attrition metrics.\n- After removing these DOB outliers, all previously identified duplicate `FullName` and `ADEmail` records were resolved, confirming that the duplicates originated from invalid DOB values.\n- The cleaned dataset now reflects only validated and realistic DOB entries, providing a sound basis for subsequent workforce analysis and EDA.","metadata":{}},{"cell_type":"markdown","source":"## 4-5. Cross-field consistency\n\nThis step validates whether `EmployeeStatus`, `ExitDate`, and `TerminationType` follow standard HR logic. Records that violate these rules below are corrected or standardized to ensure reliable attrition, tenure, and headcount reporting. \n\n### HR-consistent Mapping (Expected Relationships)\n| EmployeeStatus                       | ExitDate   | TerminationType                      | HR Logic                                   |\n| ------------------------------------ | ---------- | ------------------------------------ | ------------------------------------------ |\n| **1. Active / Leave of Absence / Future Start** | Not filled | Unk                            | Employee is still employed                 |\n| **2. Voluntarily Terminated**           | Filled     | Voluntary / Resignation              | Employee resigned voluntarily              |\n| **3. Terminated for Cause**         | Filled     | Involuntary                          | Employer-driven termination   |\n| **4. Retired**                          | Filled     | Retirement                           | Exit due to retirement                     |\n\n### ‚úîÔ∏è Steps Performed\n1. Detect inconsistencies.\n2. Correct misaligned records.\n3. Confirm that all rows conform to HR-consistent mappings after cleaning.","metadata":{}},{"cell_type":"code","source":"# Define HR logic groups (align with dataset labels)\nactive_status = ['Active', 'Future Start', 'Leave of Absence']\nvol_status    = ['Voluntarily Terminated']\ninvol_status  = ['Terminated for Cause']\nret_status    = ['Retired']\n\nactive_types      = ['Unk']\nvoluntary_types   = ['Voluntary', 'Resignation']\ninvoluntary_types = ['Involuntary']\nretirement_types  = ['Retirement']\n\n# Ensure \"Retired\" category exists\ndf[\"EmployeeStatus\"] = df[\"EmployeeStatus\"].cat.add_categories([\"Retired\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.083823Z","iopub.execute_input":"2025-12-03T02:44:32.084154Z","iopub.status.idle":"2025-12-03T02:44:32.116192Z","shell.execute_reply.started":"2025-12-03T02:44:32.084122Z","shell.execute_reply":"2025-12-03T02:44:32.114916Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 1) Active / Leave of Absence / Future Start\n# ==============================\n# Expected:\n# - ExitDate: empty\n# - TerminationType: \"Unk\"\n\n# Extract Active group\nactive_df = df[df[\"EmployeeStatus\"].isin(active_status)].copy()\n\n# Normal: no ExitDate AND TerminationType == \"Unk\"\nmask_normal = active_df[\"ExitDate\"].isna() & (active_df[\"TerminationType\"] == \"Unk\")\nnormal_active = active_df[mask_normal]\n\n# Error A1: ExitDate present (TerminationType irrelevant)\nmask_A1 = active_df[\"ExitDate\"].notna()\nerror_A1 = active_df[mask_A1]\n\n# Error A2: No ExitDate AND TerminationType != \"Unk\"\nmask_A2 = active_df[\"ExitDate\"].isna() & (active_df[\"TerminationType\"] != \"Unk\")\nerror_A2 = active_df[mask_A2]\n\n# Error A3: ExitDate present AND TerminationType != \"Unk\"\nmask_A3 = active_df[\"ExitDate\"].notna() & (active_df[\"TerminationType\"] != \"Unk\")\nerror_A3 = active_df[mask_A3]\n\nprint(\"Total Active / Leave of Absence / Future Start rows:\", len(active_df))\nprint(\"‚úÖ Normal rows:\", len(normal_active))\nprint(\"‚ùå Error A1 (Active with ExitDate):\", len(error_A1))\nprint(\"‚ùå Error A2 (No ExitDate BUT TermType != 'Unk'):\", len(error_A2))\nprint(\"‚ùå Error A3 (ExitDate exists AND TermType != 'Unk'):\", len(error_A3))\n\n# Check if A1 and A3 overlap fully\nprint(\"A1 and A3 identical?\", error_A1.equals(error_A3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.116871Z","iopub.execute_input":"2025-12-03T02:44:32.117082Z","iopub.status.idle":"2025-12-03T02:44:32.166061Z","shell.execute_reply.started":"2025-12-03T02:44:32.117061Z","shell.execute_reply":"2025-12-03T02:44:32.165053Z"}},"outputs":[{"name":"stdout","text":"Total Active / Leave of Absence / Future Start rows: 1986\n‚úÖ Normal rows: 1113\n‚ùå Error A1 (Active with ExitDate): 873\n‚ùå Error A2 (No ExitDate BUT TermType != 'Unk'): 0\n‚ùå Error A3 (ExitDate exists AND TermType != 'Unk'): 873\nA1 and A3 identical? True\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Cleaning: reclassify Active rows that actually have an ExitDate into proper terminated buckets\nmask_wrong_active = (\n    df[\"EmployeeStatus\"].isin(active_status)\n    & df[\"ExitDate\"].notna()\n    & (df[\"TerminationType\"] != \"Unk\")\n)\n\nvol_mask = mask_wrong_active & df[\"TerminationType\"].isin([\"Voluntary\", \"Resignation\"])\ninvol_mask = mask_wrong_active & (df[\"TerminationType\"] == \"Involuntary\")\nret_mask = mask_wrong_active & (df[\"TerminationType\"] == \"Retirement\")\n\ndf.loc[vol_mask, \"EmployeeStatus\"] = \"Voluntarily Terminated\"\ndf.loc[invol_mask, \"EmployeeStatus\"] = \"Terminated for Cause\"\ndf.loc[ret_mask, \"EmployeeStatus\"] = \"Retired\"\n\n# Re-validate Active group after cleaning\nactive_df_clean = df[df[\"EmployeeStatus\"].isin(active_status)].copy()\n\nmask_normal_clean = active_df_clean[\"ExitDate\"].isna() & (active_df_clean[\"TerminationType\"] == \"Unk\")\nmask_A1_clean = active_df_clean[\"ExitDate\"].notna()\nmask_A2_clean = active_df_clean[\"ExitDate\"].isna() & (active_df_clean[\"TerminationType\"] != \"Unk\")\nmask_A3_clean = active_df_clean[\"ExitDate\"].notna() & (active_df_clean[\"TerminationType\"] != \"Unk\")\n\nprint(\"After cleaning ‚Äì Active / Leave of Absence / Future Start rows:\", len(active_df_clean))\nprint(\"‚úÖ Normal rows:\", mask_normal_clean.sum())\nprint(\"‚ùå Error A1 (Active with ExitDate):\", mask_A1_clean.sum())\nprint(\"‚ùå Error A2 (No ExitDate BUT TermType != 'Unk'):\", mask_A2_clean.sum())\nprint(\"‚ùå Error A3 (ExitDate exists AND TermType != 'Unk'):\", mask_A3_clean.sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.167041Z","iopub.execute_input":"2025-12-03T02:44:32.167348Z","iopub.status.idle":"2025-12-03T02:44:32.272899Z","shell.execute_reply.started":"2025-12-03T02:44:32.167322Z","shell.execute_reply":"2025-12-03T02:44:32.272111Z"}},"outputs":[{"name":"stdout","text":"After cleaning ‚Äì Active / Leave of Absence / Future Start rows: 1113\n‚úÖ Normal rows: 1113\n‚ùå Error A1 (Active with ExitDate): 0\n‚ùå Error A2 (No ExitDate BUT TermType != 'Unk'): 0\n‚ùå Error A3 (ExitDate exists AND TermType != 'Unk'): 0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# 2) Voluntarily Terminated\n# ==============================\n# Expected:\n# - ExitDate: filled\n# - TerminationType ‚àà {\"Voluntary\", \"Resignation\"}\n\nvol_df = df[df[\"EmployeeStatus\"].isin(vol_status)].copy()\n\n# Normal: ExitDate filled AND TerminationType in Voluntary/Resignation\nmask_V_normal = vol_df[\"ExitDate\"].notna() & vol_df[\"TerminationType\"].isin(voluntary_types)\nnormal_vol = vol_df[mask_V_normal]\n\n# Error V1: missing ExitDate\nmask_V1 = vol_df[\"ExitDate\"].isna()\nerror_V1 = vol_df[mask_V1]\n\n# Error V2: wrong TerminationType\nmask_V2 = ~vol_df[\"TerminationType\"].isin(voluntary_types)\nerror_V2 = vol_df[mask_V2]\n\n# Error V3: both missing ExitDate AND wrong TerminationType\nmask_V3 = vol_df[\"ExitDate\"].isna() & (~vol_df[\"TerminationType\"].isin(voluntary_types))\nerror_V3 = vol_df[mask_V3]\n\nprint(\"Total 'Voluntarily Terminated' rows:\", len(vol_df))\nprint(\"‚úÖ Normal V (ExitDate filled & TermType in Vol/Res):\", len(normal_vol))\nprint(\"‚ùå Error V1 (VolTerm but no ExitDate):\", len(error_V1))\nprint(\"‚ùå Error V2 (VolTerm but wrong TermType):\", len(error_V2))\nprint(\"‚ùå Error V3 (VolTerm, no ExitDate & wrong TermType):\", len(error_V3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.273720Z","iopub.execute_input":"2025-12-03T02:44:32.273994Z","iopub.status.idle":"2025-12-03T02:44:32.301799Z","shell.execute_reply.started":"2025-12-03T02:44:32.273972Z","shell.execute_reply":"2025-12-03T02:44:32.300537Z"}},"outputs":[{"name":"stdout","text":"Total 'Voluntarily Terminated' rows: 696\n‚úÖ Normal V (ExitDate filled & TermType in Vol/Res): 565\n‚ùå Error V1 (VolTerm but no ExitDate): 0\n‚ùå Error V2 (VolTerm but wrong TermType): 131\n‚ùå Error V3 (VolTerm, no ExitDate & wrong TermType): 0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cleaning: standardize TerminationType for VolTerm rows\nmask_vol_status = df[\"EmployeeStatus\"] == \"Voluntarily Terminated\"\nmask_wrong_vol_type = mask_vol_status & (~df[\"TerminationType\"].isin(voluntary_types))\ndf.loc[mask_wrong_vol_type, \"TerminationType\"] = \"Voluntary\"\n\n# Re-check VolTerm after cleaning\nvol_df_clean = df[df[\"EmployeeStatus\"] == \"Voluntarily Terminated\"].copy()\n\nmask_V_normal_clean = (\n    vol_df_clean[\"ExitDate\"].notna() &\n    vol_df_clean[\"TerminationType\"].isin(voluntary_types)\n)\nmask_V1_clean = vol_df_clean[\"ExitDate\"].isna()\nmask_V2_clean = ~vol_df_clean[\"TerminationType\"].isin(voluntary_types)\nmask_V3_clean = vol_df_clean[\"ExitDate\"].isna() & (~vol_df_clean[\"TerminationType\"].isin(voluntary_types))\n\nprint(\"After cleaning ‚Äì 'Voluntarily Terminated' rows:\", len(vol_df_clean))\nprint(\"‚úÖ Normal V (ExitDate filled & TermType in Vol/Res):\", mask_V_normal_clean.sum())\nprint(\"‚ùå Error V1 (VolTerm but no ExitDate):\", mask_V1_clean.sum())\nprint(\"‚ùå Error V2 (VolTerm but wrong TermType):\", mask_V2_clean.sum())\nprint(\"‚ùå Error V3 (VolTerm, no ExitDate & wrong TermType):\", mask_V3_clean.sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.302559Z","iopub.execute_input":"2025-12-03T02:44:32.302744Z","iopub.status.idle":"2025-12-03T02:44:32.327892Z","shell.execute_reply.started":"2025-12-03T02:44:32.302729Z","shell.execute_reply":"2025-12-03T02:44:32.327128Z"}},"outputs":[{"name":"stdout","text":"After cleaning ‚Äì 'Voluntarily Terminated' rows: 696\n‚úÖ Normal V (ExitDate filled & TermType in Vol/Res): 696\n‚ùå Error V1 (VolTerm but no ExitDate): 0\n‚ùå Error V2 (VolTerm but wrong TermType): 0\n‚ùå Error V3 (VolTerm, no ExitDate & wrong TermType): 0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# 3) Involuntarily Terminated\n# ==============================\n# Expected:\n# - ExitDate: filled\n# - TerminationType = \"Involuntary\"\n\ninvol_df = df[df[\"EmployeeStatus\"].isin(invol_status)].copy()\n\n# Normal: ExitDate filled AND TerminationType == \"Involuntary\"\nmask_I_normal = invol_df[\"ExitDate\"].notna() & invol_df[\"TerminationType\"].isin(involuntary_types)\nnormal_invol = invol_df[mask_I_normal]\n\n# Error I1: missing ExitDate\nmask_I1 = invol_df[\"ExitDate\"].isna()\nerror_I1 = invol_df[mask_I1]\n\n# Error I2: wrong TerminationType\nmask_I2 = ~invol_df[\"TerminationType\"].isin(involuntary_types)\nerror_I2 = invol_df[mask_I2]\n\n# Error I3: missing ExitDate + wrong TerminationType\nmask_I3 = invol_df[\"ExitDate\"].isna() & (~invol_df[\"TerminationType\"].isin(involuntary_types))\nerror_I3 = invol_df[mask_I3]\n\nprint(\"\\nBefore cleaning ‚Äì Involuntary statuses rows:\", len(invol_df))\nprint(\"‚úÖ Normal I (ExitDate filled & TermType = Involuntary):\", len(normal_invol))\nprint(\"‚ùå Error I1 (InvolTerm but no ExitDate):\", len(error_I1))\nprint(\"‚ùå Error I2 (InvolTerm but wrong TermType):\", len(error_I2))\nprint(\"‚ùå Error I3 (InvolTerm, no ExitDate & wrong TermType):\", len(error_I3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.329266Z","iopub.execute_input":"2025-12-03T02:44:32.329496Z","iopub.status.idle":"2025-12-03T02:44:32.351903Z","shell.execute_reply.started":"2025-12-03T02:44:32.329481Z","shell.execute_reply":"2025-12-03T02:44:32.350990Z"}},"outputs":[{"name":"stdout","text":"\nBefore cleaning ‚Äì Involuntary statuses rows: 254\n‚úÖ Normal I (ExitDate filled & TermType = Involuntary): 222\n‚ùå Error I1 (InvolTerm but no ExitDate): 0\n‚ùå Error I2 (InvolTerm but wrong TermType): 32\n‚ùå Error I3 (InvolTerm, no ExitDate & wrong TermType): 0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Cleaning: standardize Involuntary termination types\nmask_invol_status = df[\"EmployeeStatus\"].isin(invol_status)\nmask_wrong_invol_type = mask_invol_status & (~df[\"TerminationType\"].isin(involuntary_types))\ndf.loc[mask_wrong_invol_type, \"TerminationType\"] = \"Involuntary\"\n\n# Re-check InvolTerm after cleaning\ninvol_df_clean = df[df[\"EmployeeStatus\"].isin(invol_status)].copy()\n\nmask_I_normal_clean = (\n    invol_df_clean[\"ExitDate\"].notna() &\n    invol_df_clean[\"TerminationType\"].isin(involuntary_types)\n)\nmask_I1_clean = invol_df_clean[\"ExitDate\"].isna()\nmask_I2_clean = ~invol_df_clean[\"TerminationType\"].isin(involuntary_types)\nmask_I3_clean = invol_df_clean[\"ExitDate\"].isna() & (~invol_df_clean[\"TerminationType\"].isin(involuntary_types))\n\nprint(\"\\nAfter cleaning ‚Äì Involuntary statuses rows:\", len(invol_df_clean))\nprint(\"‚úÖ Normal I (ExitDate filled & TermType = Involuntary):\", mask_I_normal_clean.sum())\nprint(\"‚ùå Error I1 (InvolTerm but no ExitDate):\", mask_I1_clean.sum())\nprint(\"‚ùå Error I2 (InvolTerm but wrong TermType):\", mask_I2_clean.sum())\nprint(\"‚ùå Error I3 (InvolTerm, no ExitDate & wrong TermType):\", mask_I3_clean.sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.353464Z","iopub.execute_input":"2025-12-03T02:44:32.353744Z","iopub.status.idle":"2025-12-03T02:44:32.386193Z","shell.execute_reply.started":"2025-12-03T02:44:32.353721Z","shell.execute_reply":"2025-12-03T02:44:32.385116Z"}},"outputs":[{"name":"stdout","text":"\nAfter cleaning ‚Äì Involuntary statuses rows: 254\n‚úÖ Normal I (ExitDate filled & TermType = Involuntary): 254\n‚ùå Error I1 (InvolTerm but no ExitDate): 0\n‚ùå Error I2 (InvolTerm but wrong TermType): 0\n‚ùå Error I3 (InvolTerm, no ExitDate & wrong TermType): 0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 4) Retired\n# ==============================\n# Expected:\n# - ExitDate: filled\n# - TerminationType = \"Retirement\"\n\nret_df = df[df[\"EmployeeStatus\"] == \"Retired\"].copy()\n\nmask_R_expected = ret_df[\"ExitDate\"].notna() & (ret_df[\"TerminationType\"] == \"Retirement\")\nnormal_ret = ret_df[mask_R_expected]\n\nmask_R1 = ret_df[\"ExitDate\"].isna()\nerror_R1 = ret_df[mask_R1]\n\nmask_R2 = ret_df[\"TerminationType\"] != \"Retirement\"\nerror_R2 = ret_df[mask_R2]\n\nmask_R3 = mask_R1 & mask_R2\nerror_R3 = ret_df[mask_R3]\n\nprint(\"\\nBefore cleaning ‚Äì EmployeeStatus = 'Retired' rows:\", len(ret_df))\nprint(\"‚úÖ Normal R (ExitDate filled & TerminationType = 'Retirement'):\", len(normal_ret))\nprint(\"‚ùå Error R1 (Retired but no ExitDate):\", len(error_R1))\nprint(\"‚ùå Error R2 (Retired but TerminationType != 'Retirement'):\", len(error_R2))\nprint(\"‚ùå Error R3 (Retired, no ExitDate AND wrong TerminationType):\", len(error_R3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.387068Z","iopub.execute_input":"2025-12-03T02:44:32.387419Z","iopub.status.idle":"2025-12-03T02:44:32.417316Z","shell.execute_reply.started":"2025-12-03T02:44:32.387396Z","shell.execute_reply":"2025-12-03T02:44:32.416465Z"}},"outputs":[{"name":"stdout","text":"\nBefore cleaning ‚Äì EmployeeStatus = 'Retired' rows: 217\n‚úÖ Normal R (ExitDate filled & TerminationType = 'Retirement'): 217\n‚ùå Error R1 (Retired but no ExitDate): 0\n‚ùå Error R2 (Retired but TerminationType != 'Retirement'): 0\n‚ùå Error R3 (Retired, no ExitDate AND wrong TerminationType): 0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# 5) Final HR-consistent mapping summary\n\nmask_active_group = df[\"EmployeeStatus\"].isin(active_status)\nmask_vol_group    = df[\"EmployeeStatus\"].isin(vol_status)\nmask_invol_group  = df[\"EmployeeStatus\"].isin(invol_status)\nmask_ret_group    = df[\"EmployeeStatus\"].isin(ret_status)\n\n# HR-consistent rules\nmask_rule1_valid = (\n    mask_active_group &\n    df[\"ExitDate\"].isna() &\n    (df[\"TerminationType\"] == \"Unk\")\n)\n\nmask_rule2_valid = (\n    mask_vol_group &\n    df[\"ExitDate\"].notna() &\n    df[\"TerminationType\"].isin([\"Voluntary\", \"Resignation\"])\n)\n\nmask_rule3_valid = (\n    mask_invol_group &\n    df[\"ExitDate\"].notna() &\n    (df[\"TerminationType\"] == \"Involuntary\")\n)\n\nmask_rule4_valid = (\n    mask_ret_group &\n    df[\"ExitDate\"].notna() &\n    (df[\"TerminationType\"] == \"Retirement\")\n)\n\nsummary_data = [\n    {\n        \"Rule\": \"1. Active / LOA / Future Start\",\n        \"EmployeeStatus group\": \"Active, Leave of Absence, Future Start\",\n        \"Total rows\": int(mask_active_group.sum()),\n        \"Valid (HR-consistent)\": int(mask_rule1_valid.sum()),\n        \"Invalid (violations)\": int(mask_active_group.sum() - mask_rule1_valid.sum()),\n    },\n    {\n        \"Rule\": \"2. Voluntarily Terminated\",\n        \"EmployeeStatus group\": \"Voluntarily Terminated\",\n        \"Total rows\": int(mask_vol_group.sum()),\n        \"Valid (HR-consistent)\": int(mask_rule2_valid.sum()),\n        \"Invalid (violations)\": int(mask_vol_group.sum() - mask_rule2_valid.sum()),\n    },\n    {\n        \"Rule\": \"3. Involuntarily Terminated\",\n        \"EmployeeStatus group\": \"Terminated for Cause\",\n        \"Total rows\": int(mask_invol_group.sum()),\n        \"Valid (HR-consistent)\": int(mask_rule3_valid.sum()),\n        \"Invalid (violations)\": int(mask_invol_group.sum() - mask_rule3_valid.sum()),\n    },\n    {\n        \"Rule\": \"4. Retired\",\n        \"EmployeeStatus group\": \"Retired\",\n        \"Total rows\": int(mask_ret_group.sum()),\n        \"Valid (HR-consistent)\": int(mask_rule4_valid.sum()),\n        \"Invalid (violations)\": int(mask_ret_group.sum() - mask_rule4_valid.sum()),\n    },\n]\n\nsummary_df = pd.DataFrame(summary_data)\n\nprint(\"\\nHR-consistent Mapping Final Check\")\ndisplay(summary_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.418479Z","iopub.execute_input":"2025-12-03T02:44:32.418781Z","iopub.status.idle":"2025-12-03T02:44:32.451223Z","shell.execute_reply.started":"2025-12-03T02:44:32.418758Z","shell.execute_reply":"2025-12-03T02:44:32.450045Z"}},"outputs":[{"name":"stdout","text":"\nHR-consistent Mapping Final Check\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                             Rule                    EmployeeStatus group  \\\n0  1. Active / LOA / Future Start  Active, Leave of Absence, Future Start   \n1       2. Voluntarily Terminated                  Voluntarily Terminated   \n2     3. Involuntarily Terminated                    Terminated for Cause   \n3                      4. Retired                                 Retired   \n\n   Total rows  Valid (HR-consistent)  Invalid (violations)  \n0        1113                   1113                     0  \n1         696                    696                     0  \n2         254                    254                     0  \n3         217                    217                     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rule</th>\n      <th>EmployeeStatus group</th>\n      <th>Total rows</th>\n      <th>Valid (HR-consistent)</th>\n      <th>Invalid (violations)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Active / LOA / Future Start</td>\n      <td>Active, Leave of Absence, Future Start</td>\n      <td>1113</td>\n      <td>1113</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2. Voluntarily Terminated</td>\n      <td>Voluntarily Terminated</td>\n      <td>696</td>\n      <td>696</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3. Involuntarily Terminated</td>\n      <td>Terminated for Cause</td>\n      <td>254</td>\n      <td>254</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4. Retired</td>\n      <td>Retired</td>\n      <td>217</td>\n      <td>217</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### üìå Key Insights\n\n- By systematically classifying errors (A1‚ÄìA3, V1‚ÄìV3, I1‚ÄìI3, R1‚ÄìR3) and applying HR-consistent rules, misaligned records were either corrected or structurally fixed.\n    - Records labeled as **Active but containing an ExitDate were reclassified into the correct termination groups** (Voluntary, Involuntary, Retired), ensuring statuses accurately reflect employment history.\n    - **TerminationType values were standardized** using EmployeeStatus as the source of truth, correcting cases where the type did not match the employee‚Äôs status.\n- After cleaning, all four groups (Active, Voluntary, Involuntary, Retired) fully matched the expected HR rules, with no remaining inconsistencies.\n- The dataset now reflects a **clean, HR-consistent employment lifecycle**, supporting accurate attrition, tenure, and headcount analysis.","metadata":{}},{"cell_type":"markdown","source":"## 4-6. Derived Variables\n\nWith the core cleaning steps complete, I generated several derived variables that will support the upcoming EDA and workforce metrics.\n\n**Derived in this step**\n- `IsActive`: identifies employees currently on payroll\n- `AttritionFlag`: 1 for employees who have left the company, 0 otherwise\n- `TenureDays`: number of days employed (Start‚ÜíExit for leavers, Start‚ÜíRefDate for active employees)\n\n**Created earlier in previous steps**\n- `SameDayTermination`(from 4.1 Date Validation)\n- `FullName`(from 4.3 Unique ID Check)\n- `Age`(from 4.4 Realistic DOB)","metadata":{}},{"cell_type":"code","source":"# IsActive flag\nactive_status = [\"Active\", \"Leave of Absence\", \"Future Start\"]\n\ndf[\"IsActive\"] = (\n    df[\"EmployeeStatus\"].isin(active_status)\n    & df[\"ExitDate\"].isna()\n)\n\ndf[\"IsActive\"] = df[\"IsActive\"].astype(bool)\n\nprint(\"Active employees (IsActive = True):\", df[\"IsActive\"].sum())\n\n# AttritionFlag\nterminated_status = [\n    \"Voluntarily Terminated\",\n    \"Terminated for Cause\",\n    \"Retired\",\n]\n\ndf[\"AttritionFlag\"] = np.where(\n    df[\"EmployeeStatus\"].isin(terminated_status) & df[\"ExitDate\"].notna(),\n    1,\n    0,\n).astype(int)\n\nprint(\"Employees with AttritionFlag = 1:\", df[\"AttritionFlag\"].sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.454418Z","iopub.execute_input":"2025-12-03T02:44:32.454632Z","iopub.status.idle":"2025-12-03T02:44:32.464163Z","shell.execute_reply.started":"2025-12-03T02:44:32.454619Z","shell.execute_reply":"2025-12-03T02:44:32.463128Z"}},"outputs":[{"name":"stdout","text":"Active employees (IsActive = True): 1113\nEmployees with AttritionFlag = 1: 1167\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# SameDayTermination flag check\nprint(\"Same-day terminations:\", df[\"SameDayTermination\"].sum())\n\n# TenureDays (includes 0-day separations)\ntoday = analysis_date.normalize()\n\ndf[\"TenureDays\"] = np.nan\n\n# For terminated employees\nmask_has_exit = df[\"StartDate\"].notna() & df[\"ExitDate\"].notna()\ndf.loc[mask_has_exit, \"TenureDays\"] = (\n    df.loc[mask_has_exit, \"ExitDate\"] - df.loc[mask_has_exit, \"StartDate\"]\n).dt.days\n\n# For active employees\nmask_active_no_exit = df[\"StartDate\"].notna() & df[\"ExitDate\"].isna()\ndf.loc[mask_active_no_exit, \"TenureDays\"] = (\n    today - df.loc[mask_active_no_exit, \"StartDate\"]\n).dt.days\n\n# Same-day terminations = 0 tenure\ndf.loc[df[\"SameDayTermination\"], \"TenureDays\"] = 0\n\ndf[\"TenureDays\"] = df[\"TenureDays\"].astype(\"Int64\")\n\nprint(\"Zero-day separations:\", (df[\"TenureDays\"] == 0).sum())\n\n\n# Negative tenure check (sanity check)\nnegative_tenure_count = (df[\"TenureDays\"] < 0).sum()\nprint(\"\\nNegative tenure count:\", negative_tenure_count)\n\nprint(\"\\nShape:\", df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.465023Z","iopub.execute_input":"2025-12-03T02:44:32.465280Z","iopub.status.idle":"2025-12-03T02:44:32.489722Z","shell.execute_reply.started":"2025-12-03T02:44:32.465254Z","shell.execute_reply":"2025-12-03T02:44:32.488932Z"}},"outputs":[{"name":"stdout","text":"Same-day terminations: 5\nZero-day separations: 5\n\nNegative tenure count: 0\n\nShape: (2280, 24)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### üìå Key Insights\n\n- Derived variables were created only after the core cleaning steps were completed, ensuring they accurately reflect the cleaned and corrected employment lifecycle.\n- **IsActive (1113) and AttritionFlag = 1 (1167) sum to the total dataset size (2280)**, confirming all employees are consistently classified with no lifecycle gaps.\n- Before cleaning, there were 6 same-day hire/termination cases. During debugging, I confirmed that the reduced count (5) was **directly caused by the Realistic DOB cleaning rule**, which removed one employee aged 70+. This expected change highlights the importance of revalidating derived metrics after all cleaning steps.\n- No negative-tenure records remain, confirming clean and valid employment timelines.\n- The final cleaned dataset now includes **24 well-defined columns**, ready for a reliable workforce EDA.","metadata":{}},{"cell_type":"markdown","source":"# 5. Finalize Column Structure\n\nOrganizing columns ensures a clean and consistent analysis workflow.","metadata":{}},{"cell_type":"code","source":"# Check current columns\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.490422Z","iopub.execute_input":"2025-12-03T02:44:32.490580Z","iopub.status.idle":"2025-12-03T02:44:32.511720Z","shell.execute_reply.started":"2025-12-03T02:44:32.490565Z","shell.execute_reply":"2025-12-03T02:44:32.510627Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Index(['EmpID', 'StartDate', 'ExitDate', 'BusinessUnit', 'DepartmentType',\n       'EmployeeStatus', 'EmployeeType', 'TerminationType', 'Title',\n       'Division', 'PayZone', 'DOB', 'GenderCode', 'RaceDesc', 'LocationCode',\n       'FirstName', 'LastName', 'ADEmail', 'SameDayTermination', 'FullName',\n       'Age', 'IsActive', 'AttritionFlag', 'TenureDays'],\n      dtype='object')"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Define the desired column order\ncols_order = [\n    # --- Identity ---\n    'EmpID', 'FirstName', 'LastName', 'FullName', 'ADEmail',\n\n    # --- Employment Dates & Status ---\n    'StartDate', 'ExitDate', 'EmployeeStatus', 'IsActive', 'AttritionFlag',\n\n    # --- Derived Metrics ---\n    'TenureDays', 'SameDayTermination', 'Age',\n\n    # --- Job / Org Details ---\n    'Title', 'BusinessUnit', 'DepartmentType', 'Division',\n    'EmployeeType', 'PayZone', 'TerminationType',\n\n    # --- Demographics ---\n    'DOB', 'GenderCode', 'RaceDesc', 'LocationCode'\n]\n# Keep only the columns that actually exist in the dataframe\ncols_order = [c for c in cols_order if c in df.columns]\n\n# Reorder dataframe columns\ndf = df[cols_order]\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.512916Z","iopub.execute_input":"2025-12-03T02:44:32.513203Z","iopub.status.idle":"2025-12-03T02:44:32.549058Z","shell.execute_reply.started":"2025-12-03T02:44:32.513182Z","shell.execute_reply":"2025-12-03T02:44:32.547492Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   EmpID FirstName LastName         FullName                        ADEmail  \\\n0   3427     Uriah  Bridges    Uriah_Bridges    uriah.bridges@bilearner.com   \n1   3428     Paula    Small      Paula_Small      paula.small@bilearner.com   \n2   3429    Edward     Buck      Edward_Buck      edward.buck@bilearner.com   \n3   3430   Michael  Riordan  Michael_Riordan  michael.riordan@bilearner.com   \n4   3431   Jasmine    Onque    Jasmine_Onque    jasmine.onque@bilearner.com   \n\n   StartDate ExitDate EmployeeStatus  IsActive  AttritionFlag  TenureDays  \\\n0 2021-12-20      NaT         Active      True              0        1437   \n1 2025-05-11      NaT         Active      True              0         199   \n2 2021-03-10      NaT         Active      True              0        1722   \n3 2023-09-21      NaT         Active      True              0         797   \n4 2021-09-29      NaT         Active      True              0        1519   \n\n   SameDayTermination   Age                    Title BusinessUnit  \\\n0               False  56.1  Production Technician I         CCDR   \n1               False  60.2  Production Technician I           EW   \n2               False  34.1       Area Sales Manager           PL   \n3               False  27.6       Area Sales Manager         CCDR   \n4               False  56.2       Area Sales Manager          TNS   \n\n  DepartmentType              Division EmployeeType PayZone TerminationType  \\\n0     Production  Finance & Accounting     Contract  Zone C             Unk   \n1     Production                Aerial     Contract  Zone A             Unk   \n2          Sales         General - Sga    Full-Time  Zone B             Unk   \n3          Sales  Finance & Accounting     Contract  Zone A             Unk   \n4          Sales         General - Con     Contract  Zone A             Unk   \n\n         DOB GenderCode  RaceDesc  LocationCode  \n0 1969-10-07     Female     White         34904  \n1 1965-08-30       Male  Hispanic          6593  \n2 1991-10-06       Male  Hispanic          2330  \n3 1998-04-04       Male     Other         58782  \n4 1969-08-29     Female     Other         33174  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EmpID</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n      <th>FullName</th>\n      <th>ADEmail</th>\n      <th>StartDate</th>\n      <th>ExitDate</th>\n      <th>EmployeeStatus</th>\n      <th>IsActive</th>\n      <th>AttritionFlag</th>\n      <th>TenureDays</th>\n      <th>SameDayTermination</th>\n      <th>Age</th>\n      <th>Title</th>\n      <th>BusinessUnit</th>\n      <th>DepartmentType</th>\n      <th>Division</th>\n      <th>EmployeeType</th>\n      <th>PayZone</th>\n      <th>TerminationType</th>\n      <th>DOB</th>\n      <th>GenderCode</th>\n      <th>RaceDesc</th>\n      <th>LocationCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3427</td>\n      <td>Uriah</td>\n      <td>Bridges</td>\n      <td>Uriah_Bridges</td>\n      <td>uriah.bridges@bilearner.com</td>\n      <td>2021-12-20</td>\n      <td>NaT</td>\n      <td>Active</td>\n      <td>True</td>\n      <td>0</td>\n      <td>1437</td>\n      <td>False</td>\n      <td>56.1</td>\n      <td>Production Technician I</td>\n      <td>CCDR</td>\n      <td>Production</td>\n      <td>Finance &amp; Accounting</td>\n      <td>Contract</td>\n      <td>Zone C</td>\n      <td>Unk</td>\n      <td>1969-10-07</td>\n      <td>Female</td>\n      <td>White</td>\n      <td>34904</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3428</td>\n      <td>Paula</td>\n      <td>Small</td>\n      <td>Paula_Small</td>\n      <td>paula.small@bilearner.com</td>\n      <td>2025-05-11</td>\n      <td>NaT</td>\n      <td>Active</td>\n      <td>True</td>\n      <td>0</td>\n      <td>199</td>\n      <td>False</td>\n      <td>60.2</td>\n      <td>Production Technician I</td>\n      <td>EW</td>\n      <td>Production</td>\n      <td>Aerial</td>\n      <td>Contract</td>\n      <td>Zone A</td>\n      <td>Unk</td>\n      <td>1965-08-30</td>\n      <td>Male</td>\n      <td>Hispanic</td>\n      <td>6593</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3429</td>\n      <td>Edward</td>\n      <td>Buck</td>\n      <td>Edward_Buck</td>\n      <td>edward.buck@bilearner.com</td>\n      <td>2021-03-10</td>\n      <td>NaT</td>\n      <td>Active</td>\n      <td>True</td>\n      <td>0</td>\n      <td>1722</td>\n      <td>False</td>\n      <td>34.1</td>\n      <td>Area Sales Manager</td>\n      <td>PL</td>\n      <td>Sales</td>\n      <td>General - Sga</td>\n      <td>Full-Time</td>\n      <td>Zone B</td>\n      <td>Unk</td>\n      <td>1991-10-06</td>\n      <td>Male</td>\n      <td>Hispanic</td>\n      <td>2330</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3430</td>\n      <td>Michael</td>\n      <td>Riordan</td>\n      <td>Michael_Riordan</td>\n      <td>michael.riordan@bilearner.com</td>\n      <td>2023-09-21</td>\n      <td>NaT</td>\n      <td>Active</td>\n      <td>True</td>\n      <td>0</td>\n      <td>797</td>\n      <td>False</td>\n      <td>27.6</td>\n      <td>Area Sales Manager</td>\n      <td>CCDR</td>\n      <td>Sales</td>\n      <td>Finance &amp; Accounting</td>\n      <td>Contract</td>\n      <td>Zone A</td>\n      <td>Unk</td>\n      <td>1998-04-04</td>\n      <td>Male</td>\n      <td>Other</td>\n      <td>58782</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3431</td>\n      <td>Jasmine</td>\n      <td>Onque</td>\n      <td>Jasmine_Onque</td>\n      <td>jasmine.onque@bilearner.com</td>\n      <td>2021-09-29</td>\n      <td>NaT</td>\n      <td>Active</td>\n      <td>True</td>\n      <td>0</td>\n      <td>1519</td>\n      <td>False</td>\n      <td>56.2</td>\n      <td>Area Sales Manager</td>\n      <td>TNS</td>\n      <td>Sales</td>\n      <td>General - Con</td>\n      <td>Contract</td>\n      <td>Zone A</td>\n      <td>Unk</td>\n      <td>1969-08-29</td>\n      <td>Female</td>\n      <td>Other</td>\n      <td>33174</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# 6. Export Cleaned Dataset\n\nThis cleaned file will be used in **Notebook 2 ‚Äì HR Workforce analysis**.","metadata":{}},{"cell_type":"code","source":"df.to_csv(\"cleaned_employee_data.csv\", index=False)\nprint(\"Cleaned dataset saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:44:32.550498Z","iopub.execute_input":"2025-12-03T02:44:32.550801Z","iopub.status.idle":"2025-12-03T02:44:32.586132Z","shell.execute_reply.started":"2025-12-03T02:44:32.550778Z","shell.execute_reply":"2025-12-03T02:44:32.585058Z"}},"outputs":[{"name":"stdout","text":"Cleaned dataset saved!\n","output_type":"stream"}],"execution_count":26}]}